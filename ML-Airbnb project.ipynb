{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                                            7087327\n",
      "listing_url                                      https://www.airbnb.com/rooms/7087327\n",
      "scrape_id                                                              20151002231825\n",
      "last_scraped                                                               2015-10-03\n",
      "name                                               Historic DC Condo-Walk to Capitol!\n",
      "summary                             Professional pictures coming soon! Welcome to ...\n",
      "space                                                                             NaN\n",
      "description                         Professional pictures coming soon! Welcome to ...\n",
      "experiences_offered                                                              none\n",
      "neighborhood_overview                                                             NaN\n",
      "notes                                                                             NaN\n",
      "transit                                                                           NaN\n",
      "thumbnail_url                       https://a2.muscache.com/ac/pictures/105507202/...\n",
      "medium_url                          https://a2.muscache.com/im/pictures/105507202/...\n",
      "picture_url                         https://a2.muscache.com/ac/pictures/105507202/...\n",
      "xl_picture_url                      https://a2.muscache.com/ac/pictures/105507202/...\n",
      "host_id                                                                      15830506\n",
      "host_url                                   https://www.airbnb.com/users/show/15830506\n",
      "host_name                                                                 Lize & Greg\n",
      "host_since                                                                 2014-05-21\n",
      "host_location                         Washington, District of Columbia, United States\n",
      "host_about                          We are two fun, friendly entrepreneurs living ...\n",
      "host_response_time                                                 within a few hours\n",
      "host_response_rate                                                                92%\n",
      "host_acceptance_rate                                                              91%\n",
      "host_is_superhost                                                                   f\n",
      "host_thumbnail_url                  https://a1.muscache.com/ac/users/15830506/prof...\n",
      "host_picture_url                    https://a1.muscache.com/ac/users/15830506/prof...\n",
      "host_neighbourhood                                                     Truxton Circle\n",
      "host_listings_count                                                                26\n",
      "                                                          ...                        \n",
      "guests_included                                                                     1\n",
      "extra_people                                                                    $0.00\n",
      "minimum_nights                                                                      1\n",
      "maximum_nights                                                                   1125\n",
      "calendar_updated                                                                today\n",
      "has_availability                                                                    t\n",
      "availability_30                                                                     0\n",
      "availability_60                                                                     0\n",
      "availability_90                                                                     8\n",
      "availability_365                                                                  283\n",
      "calendar_last_scraped                                                      2015-10-02\n",
      "number_of_reviews                                                                   0\n",
      "first_review                                                                      NaN\n",
      "last_review                                                                       NaN\n",
      "review_scores_rating                                                              NaN\n",
      "review_scores_accuracy                                                            NaN\n",
      "review_scores_cleanliness                                                         NaN\n",
      "review_scores_checkin                                                             NaN\n",
      "review_scores_communication                                                       NaN\n",
      "review_scores_location                                                            NaN\n",
      "review_scores_value                                                               NaN\n",
      "requires_license                                                                    f\n",
      "license                                                                           NaN\n",
      "jurisdiction_names                                   DISTRICT OF COLUMBIA, WASHINGTON\n",
      "instant_bookable                                                                    f\n",
      "cancellation_policy                                                          flexible\n",
      "require_guest_profile_picture                                                       f\n",
      "require_guest_phone_verification                                                    f\n",
      "calculated_host_listings_count                                                     18\n",
      "reviews_per_month                                                                 NaN\n",
      "Name: 0, Length: 92, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dc_listings = pd.read_csv('/Users/eleonoreserge/Documents/listings.csv')\n",
    "print(dc_listings.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's the strategy we wanted to use:\n",
    "\n",
    "Find a few similar listings.\n",
    "Calculate the average nightly rental price of these listings.\n",
    "Set the average price as the price for our listing.\n",
    "The k-nearest neighbors algorithm is similar to this strategy.\n",
    "\n",
    "## Euclidean distance \n",
    "\n",
    "When trying to predict a continuous value, like price, the main similarity metric that's used is Euclidean distance. Here's the general formula for Euclidean distance:\n",
    "\n",
    "d = \\sqrt{(q_1-p_1)^2 + (q_2-p_2)^2 +...+ (q_n-p_n)^2}\n",
    "\n",
    "where q_1 to q_n represent the feature values for one observation and p_1 to p_n represent the feature values for the other observation. \n",
    "\n",
    "Here, to keep things simple, we'll use just one feature. Since we're only using one feature, this is known as the univariate case. Here's what the formula looks like for the univariate case:\n",
    "\n",
    "d = \\sqrt{(q_1 - p_1)^2}\n",
    "\n",
    "The living space that we want to rent can accommodate 3 people. Let's first calculate the distance, using just the accommodates feature, between the first living space in the dataset and our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "## Euclidean distance ##\n",
    "\n",
    "import numpy as np\n",
    "our_acc_value = 3\n",
    "first_living_space_value = dc_listings.iloc[0]['accommodates']\n",
    "first_distance = np.abs(first_living_space_value - our_acc_value)\n",
    "print(first_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Euclidean distance between the first row in the dc_listings Dataframe and our own living space is 1. How do we know if this is high or low? If you look at the Euclidean distance equation itself, the lowest value you can achieve is 0. \n",
    "The closer to 0 the distance the more similar the living spaces are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate distance for all observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     2294\n",
      "2      503\n",
      "0      461\n",
      "3      279\n",
      "5       73\n",
      "4       35\n",
      "7       22\n",
      "6       17\n",
      "9       12\n",
      "13       8\n",
      "8        7\n",
      "12       6\n",
      "11       4\n",
      "10       2\n",
      "Name: distance, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "new_listing = 3\n",
    "dc_listings['distance'] = dc_listings['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "print(dc_listings['distance'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that there are 461 living spaces that can accomodate 3 people just like ours (Value 0).\n",
    "This means the 5 \"nearest neighbors\" we select after sorting all will have a distance value of 0. If we sort by the distance column and then just select the first 5 living spaces, we would be biasing the result to the ordering of the dataset.\n",
    "\n",
    "Let's instead randomize the ordering of the dataset and then sort the Dataframe by the distance column. This way, all of the living spaces with the same number of bedrooms will still be at the top of the Dataframe but will be in random order across the first 461 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577     $185.00\n",
      "2166    $180.00\n",
      "3631    $175.00\n",
      "71      $128.00\n",
      "1011    $115.00\n",
      "380     $219.00\n",
      "943     $125.00\n",
      "3107    $250.00\n",
      "1499     $94.00\n",
      "625     $150.00\n",
      "Name: price, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Randomizing, and sorting ##\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "dc_listings = dc_listings.sort_values('distance')\n",
    "print(dc_listings.iloc[0:10]['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average price\n",
    "\n",
    "Before we can select the 5 most similar living spaces and compute the average price, we need to clean the price column. Right now, the price column contains comma characters (,) and dollar sign characters and is formatted as a text column instead of a numeric one. We need to remove these values and convert the entire column to the float datatype. Then, we can calculate the average price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.6\n"
     ]
    }
   ],
   "source": [
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "mean_price = dc_listings.iloc[0:5]['price'].mean()\n",
    "print(mean_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Based on the average price of other listings that accommdate 3 people, we should charge 156.6 dollars per night for a guest to stay at our living space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to make predictions\n",
    "\n",
    "Let's write a more general function that can suggest the optimal price for other values of the accommodates column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.8\n",
      "96.8\n",
      "96.0\n"
     ]
    }
   ],
   "source": [
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "\n",
    "def predict_price(new_listing):\n",
    "    temp_df = dc_listings.copy()\n",
    "   \n",
    "    return(new_listing)\n",
    "acc_one = predict_price(1)\n",
    "acc_two = predict_price(2)\n",
    "acc_four = predict_price(4)\n",
    "def predict_price(new_listing):\n",
    "    temp_df = dc_listings.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbors = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbors.mean()\n",
    "    return(predicted_price)\n",
    "\n",
    "acc_one = predict_price(1)\n",
    "acc_two = predict_price(2)\n",
    "acc_four = predict_price(4)\n",
    "print(acc_one)\n",
    "print(acc_two)\n",
    "print(acc_four)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a function that can predict the price for any living space we want to list as long as we know the number of people it can accommodate. The function we wrote represents a machine learning model, which means that it outputs a prediction based on the input to the model.\n",
    "\n",
    "We just used a simple k-nearest neighbors machine learning model that used just one feature, or attribute, of the listing to predict the rent price.\n",
    "\n",
    "Now we have to point out that using just a single feature to compare listings doesn't reflect the reality of the market. An apartment that can accommodate 4 guests in a popular part of Washington D.C. will rent for much higher than one that can accommodate 4 guests in a crime ridden area.\n",
    "\n",
    "There are 2 ways we can tweak the model to try to improve the accuracy (decrease the RMSE during validation):\n",
    "\n",
    "- increase the number of attributes the model uses to calculate similarity when ranking the closest neighbors\n",
    "- increase k, the number of nearby neighbors the model uses when computing the prediction\n",
    "\n",
    "we'll focus on increasing the number of attributes the model uses.\n",
    "\n",
    "When selecting more attributes to use in the model, we need to watch out for columns that don't work well with the distance equation. This includes columns containing:\n",
    "\n",
    "- non-numerical values (e.g. city or state)\n",
    "Euclidean distance equation expects numerical values\n",
    "- missing values\n",
    "distance equation expects a value for each observation and attribute\n",
    "- non-ordinal values (e.g. latitude or longitude)\n",
    "ranking by Euclidean distance doesn't make sense if all attributes aren't ordinal\n",
    "\n",
    "Let's first look at the first row's values to identify any columns containing non-numerical or non-ordinal values.\n",
    "We use the DataFrame.info() method to return the number of non-null values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3723 entries, 574 to 1061\n",
      "Data columns (total 19 columns):\n",
      "host_response_rate      3289 non-null object\n",
      "host_acceptance_rate    3109 non-null object\n",
      "host_listings_count     3723 non-null int64\n",
      "accommodates            3723 non-null int64\n",
      "room_type               3723 non-null object\n",
      "bedrooms                3702 non-null float64\n",
      "bathrooms               3696 non-null float64\n",
      "beds                    3712 non-null float64\n",
      "price                   3723 non-null float64\n",
      "cleaning_fee            2335 non-null object\n",
      "security_deposit        1426 non-null object\n",
      "minimum_nights          3723 non-null int64\n",
      "maximum_nights          3723 non-null int64\n",
      "number_of_reviews       3723 non-null int64\n",
      "latitude                3723 non-null float64\n",
      "longitude               3723 non-null float64\n",
      "city                    3723 non-null object\n",
      "zipcode                 3714 non-null object\n",
      "state                   3723 non-null object\n",
      "dtypes: float64(6), int64(5), object(8)\n",
      "memory usage: 581.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "dc_listings = pd.read_csv('/Users/eleonoreserge/Documents/dc_airbnb.csv')\n",
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "print(dc_listings.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing features\n",
    "\n",
    "The following columns contain non-numerical values:\n",
    "\n",
    "- room_type: e.g. Private room\n",
    "- city: e.g. Washington\n",
    "- state: e.g. DC\n",
    "\n",
    "while these columns contain numerical but non-ordinal values:\n",
    "\n",
    "- latitude: e.g. 38.913458\n",
    "- longitude: e.g. -77.031\n",
    "- zipcode: e.g. 20009\n",
    "\n",
    "While we could convert the host_response_rate and host_acceptance_rate columns to be numerical (right now they're object data types and contain the % sign), these columns describe the host and not the living space itself. Let's avoid using any columns that don't directly describe the living space or the listing itself:\n",
    "\n",
    "- host_response_rate\n",
    "- host_acceptance_rate\n",
    "- host_listings_count\n",
    "\n",
    "Let's remove these 9 columns from the Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accommodates            0\n",
      "bedrooms               21\n",
      "bathrooms              27\n",
      "beds                   11\n",
      "price                   0\n",
      "cleaning_fee         1388\n",
      "security_deposit     2297\n",
      "minimum_nights          0\n",
      "maximum_nights          0\n",
      "number_of_reviews       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['room_type', 'city', 'state', 'latitude', 'longitude', 'zipcode', 'host_response_rate', 'host_acceptance_rate', 'host_listings_count']\n",
    "dc_listings = dc_listings.drop(drop_columns, axis=1)\n",
    "print(dc_listings.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the remaining columns, 3 columns have a few missing values (less than 1% of the total number of rows):\n",
    "\n",
    "- bedrooms\n",
    "- bathrooms\n",
    "- beds\n",
    "Since the number of rows containing missing values for one of these 3 columns is low, we can select and remove those rows without losing much information. There are also 2 columns that have a large number of missing values:\n",
    "\n",
    "- cleaning_fee  37.3% of the rows\n",
    "- security_deposit  61.7% of the rows\n",
    "\n",
    "and we can't handle these easily. We can't just remove the rows containing missing values for these 2 columns because we'd miss out on the majority of the observations in the dataset. Instead, let's remove these 2 columns entirely from consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accommodates         0\n",
      "bedrooms             0\n",
      "bathrooms            0\n",
      "beds                 0\n",
      "price                0\n",
      "minimum_nights       0\n",
      "maximum_nights       0\n",
      "number_of_reviews    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dc_listings = dc_listings.drop(['cleaning_fee', 'security_deposit'], axis=1)\n",
    "dc_listings = dc_listings.dropna(axis=0)\n",
    "print(dc_listings.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize columns\n",
    "\n",
    "To prevent any single column from having too much of an impact on the distance, we can normalize all of the columns to have a mean of 0 and a standard deviation of 1 :\n",
    "\n",
    "- from each value, subtract the mean of the column\n",
    "- divide each value by the standard deviation of the column\n",
    "\n",
    "apply this transformation across all of the columns in a Dataframe, we can use the corresponding Dataframe methods mean() and std()\n",
    "\n",
    "Let's now normalize all of the feature columns in dc_listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      accommodates  bedrooms  bathrooms      beds  price  minimum_nights  \\\n",
      "574      -0.596544 -0.249467  -0.439151 -0.546858  125.0       -0.341375   \n",
      "1593     -0.596544 -0.249467   0.412923 -0.546858   85.0       -0.341375   \n",
      "3091     -1.095499 -0.249467  -1.291226 -0.546858   50.0       -0.341375   \n",
      "\n",
      "      maximum_nights  number_of_reviews  \n",
      "574        -0.016604           4.579650  \n",
      "1593       -0.016603           1.159275  \n",
      "3091       -0.016573          -0.482505  \n"
     ]
    }
   ],
   "source": [
    "normalized_listings = (dc_listings - dc_listings.mean())/(dc_listings.std())\n",
    "normalized_listings['price'] = dc_listings['price']\n",
    "print(normalized_listings.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Euclidean distance for multivariate case\n",
    "\n",
    "Let's now train a model that uses both attributes when determining how similar 2 living spaces are. Let's refer to the Euclidean distance equation again to see what the distance calculation using 2 attributes would look like:\n",
    "\n",
    "d = \\sqrt{(accommodates_1-accommodates_2)^2 + (bathrooms_1-bathrooms_2)^2 }\n",
    "\n",
    "So far, we've been calculating Euclidean distance ourselves by writing the logic for the equation ourselves. We can instead use the distance.euclidean() function from scipy.spatial, which takes in 2 vectors as the parameters and calculates the Euclidean distance between them. The euclidean() function expects:\n",
    "\n",
    "- both of the vectors to be represented using a list-like object (Python list, NumPy array, or pandas Series)\n",
    "- both of the vectors must be 1-dimensional and have the same number of elements\n",
    "\n",
    "Let's use the euclidean() function to calculate the Euclidean distance between 2 rows in our dataset to practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.272543124668404\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "first_listing = normalized_listings.iloc[0][['accommodates', 'bathrooms']]\n",
    "fifth_listing = normalized_listings.iloc[4][['accommodates', 'bathrooms']]\n",
    "first_fifth_distance = distance.euclidean(first_listing, fifth_listing)\n",
    "print(first_fifth_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn\n",
    "\n",
    "The scikit-learn workflow consists of 4 main steps:\n",
    "\n",
    "- instantiate the specific machine learning model you want to use\n",
    "- fit the model to the training data\n",
    "- use the model to make predictions\n",
    "- evaluate the accuracy of the predictions\n",
    "\n",
    "Each model in scikit-learn is implemented as a separate class and the first step is to identify the class we want to create an instance of. In our case, we want to use the KNeighborsRegressor class.\n",
    "\n",
    "Any model that helps us predict numerical values, like listing price in our case, is known as a regression model. The other main class of machine learning models is called classification, where we're trying to predict a label from a fixed set of labels (e.g. blood type or gender).\n",
    "\n",
    "Scikit-learn uses a similar object-oriented style to Matplotlib and you need to instantiate an empty model first by calling the constructor:\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "- n_neighbors: the number of neighbors, is set to 5\n",
    "- algorithm: for computing nearest neighbors, is set to auto\n",
    "- p: set to 2, corresponding to Euclidean distance\n",
    "\n",
    "Let's set the algorithm parameter to brute and leave the n_neighbors value as 5. If we leave the algorithm parameter set to the default value of auto, scikit-learn will try to use tree-based optimizations to improve performance (which are outside of the scope of our task)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a model and making predictions\n",
    "\n",
    "Now, we can fit the model to the data using the fit method.\n",
    "\n",
    "Now that we specified the training data we want used to make predictions, we can use the predict method to make predictions on the test set.\n",
    "\n",
    "The number of feature columns you use during both training and testing need to match or scikit-learn will return an error.\n",
    "The predict() method returns a NumPy array containing the predicted price values for the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "train_df = normalized_listings.iloc[0:2792]\n",
    "test_df = normalized_listings.iloc[2792:]\n",
    "train_columns = ['accommodates', 'bathrooms']\n",
    "\n",
    "# Instantiate ML model.\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "\n",
    "# Fit model to data.\n",
    "knn.fit(train_df[train_columns], train_df['price'])\n",
    "\n",
    "# Use model to make predictions.\n",
    "predictions = knn.predict(test_df[train_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating MSE using Scikit-Learn\n",
    "\n",
    "we can use the sklearn.metrics.mean_squared_error function(). calculated the MSE and RMSE values.\n",
    "\n",
    "The mean_squared_error() function takes in 2 inputs:\n",
    "\n",
    "- list-like object, representing the true values\n",
    "- list-like object, representing the predicted values using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15660.39795221843\n",
      "125.14151170662127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_columns = ['accommodates', 'bathrooms']\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute', metric='euclidean')\n",
    "knn.fit(train_df[train_columns], train_df['price'])\n",
    "predictions = knn.predict(test_df[train_columns])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "two_features_mse = mean_squared_error(test_df['price'], predictions)\n",
    "two_features_rmse = two_features_mse ** (1/2)\n",
    "print(two_features_mse)\n",
    "print(two_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using more features\n",
    "\n",
    "The model we trained using both features ended up performing better (lower error score) than either of the univariate models\n",
    "\n",
    "Let's now train a model using the following 4 features:\n",
    "\n",
    "- accommodates\n",
    "- bedrooms\n",
    "- bathrooms\n",
    "- number_of_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13320.230625711036\n",
      "115.41330350402\n"
     ]
    }
   ],
   "source": [
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "knn.fit(train_df[features], train_df['price'])\n",
    "four_predictions = knn.predict(test_df[features])\n",
    "four_mse = mean_squared_error(test_df['price'], four_predictions)\n",
    "four_rmse = four_mse ** (1/2)\n",
    "print(four_mse)\n",
    "print(four_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good! As we increased the features the model used, we observed lower MSE and RMSE values.\n",
    "But selecting the right features is important and that using more features doesn't automatically improve prediction accuracy. \n",
    "For example,when we used all of the features available to us the RMSE value actually increased to 124.\n",
    "Feature selection = important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15455.275631399316\n",
      "124.31924883701363\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "\n",
    "features = train_df.columns.tolist()\n",
    "features.remove('price')\n",
    "\n",
    "knn.fit(train_df[features], train_df['price'])\n",
    "all_features_predictions = knn.predict(test_df[features])\n",
    "all_features_mse = mean_squared_error(test_df['price'], all_features_predictions)\n",
    "all_features_rmse = all_features_mse ** (1/2)\n",
    "print(all_features_mse)\n",
    "print(all_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "We prepared the data to be able to use more features, trained a few models using multiple features. We explored how using more features doesn't always improve the accuracy of a k-nearest neighbors model. Now, we'll explore another knob for tuning k-nearest neighbor models - the k value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll focus on the impact of increasing k, the number of nearby neighbors the model uses to make predictions. \n",
    "Traning (dc_airbnb_train.csv) and test (dc_airbnb_test.csv) sets.\n",
    "Let's read both these CSV's into Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('/Users/eleonoreserge/Documents/dc_airbnb_train.csv')\n",
    "test_df = pd.read_csv('/Users/eleonoreserge/Documents/dc_airbnb_test.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization\n",
    "\n",
    "When we vary the features that are used in the model, we're affecting the data that the model uses. On the other hand, varying the k value affects the behavior of the model independently of the actual data that's used when making predictions. In other words, we're impacting how the model performs without trying to change the data that's used.\n",
    "\n",
    "Hyperparameters : Values that affect the behavior and performance of a model that are unrelated to the data that's used\n",
    "\n",
    "## Grid search\n",
    "A simple but common hyperparameter optimization technique is known as grid search.\n",
    "Grid search essentially boils down to evaluating the model performance at different k values and selecting the k value that resulted in the lowest error. \n",
    "\n",
    "Let's confirm that grid search will work quickly for the dataset we're working with by first observing how the model performance changes as we increase the k value from 1 to 5. \n",
    "\n",
    "Let's use the features that resulted in the best model accuracy:\n",
    "\n",
    "- accommodates\n",
    "- bedrooms\n",
    "- bathrooms\n",
    "- number_of_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26364.92832764505, 15100.52246871445, 14579.597901655923, 16212.300767918088, 14090.011649601822]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "hyper_params = [1, 2, 3, 4, 5]\n",
    "mse_values = list()\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "print(mse_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increased the k value from 1 to 5, the MSE value fell from approximately 26364 to approximately 14090.\n",
    "\n",
    "Let's expand grid search all the way to a k value of 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26364.92832764505, 15100.52246871445, 14579.597901655923, 16212.300767918088, 14090.011649601822, 13657.45250284414, 14288.273896589353, 14853.448183304892, 14670.831907751512, 14642.451478953355, 14734.071380889252, 14854.802332195677, 14733.16190399257, 14777.975894453346, 14771.171543420554, 14870.178509847838, 14830.55072806075, 14782.595763283192, 14773.558705907935, 14676.544189419797]\n"
     ]
    }
   ],
   "source": [
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "hyper_params = [x for x in range(1, 21)]\n",
    "mse_values = list()\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "print(mse_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increased the k value from 1 to 6, the MSE value decreased from approximately 26364 to approximately 13657. However, as we increased the k value from 7 to 20, the MSE value didn't decrease further but instead hovered between approximately 14288 and 14870. This means that the optimal k value is 6, since it resulted in the lowest MSE value.\n",
    "\n",
    "## Visualizing hyperparameter values\n",
    "\n",
    "Let's confirm this behavior visually using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "hyper_params = [x for x in range(1, 21)]\n",
    "mse_values = list()\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "plt.scatter(hyper_params, mse_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scatter plot, you can tell that the lowest MSE value was achieved at the k value of 6.\n",
    "\n",
    "the general workflow for finding the best model is:\n",
    "\n",
    "- select relevant features to use for predicting the target column.\n",
    "- use grid search to find the optimal hyperparameter value for the selected features.\n",
    "- evaluate the model's accuracy and repeat the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow of finding the optimal model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: 14790.314266211606}\n",
      "{5: 13522.893333333333}\n"
     ]
    }
   ],
   "source": [
    "two_features = ['accommodates', 'bathrooms']\n",
    "three_features = ['accommodates', 'bathrooms', 'bedrooms']\n",
    "hyper_params = [x for x in range(1,21)]\n",
    "# Append the first model's MSE values to this list.\n",
    "two_mse_values = list()\n",
    "# Append the second model's MSE values to this list.\n",
    "three_mse_values = list()\n",
    "two_hyp_mse = dict()\n",
    "three_hyp_mse = dict()\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[two_features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[two_features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    two_mse_values.append(mse)\n",
    "\n",
    "two_lowest_mse = two_mse_values[0]\n",
    "two_lowest_k = 1\n",
    "\n",
    "for k,mse in enumerate(two_mse_values):\n",
    "    if mse < two_lowest_mse:\n",
    "        two_lowest_mse = mse\n",
    "        two_lowest_k = k + 1\n",
    "    \n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[three_features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[three_features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    three_mse_values.append(mse)\n",
    "    \n",
    "three_lowest_mse = three_mse_values[0]\n",
    "three_lowest_k = 1\n",
    "\n",
    "for k,mse in enumerate(three_mse_values):\n",
    "    if mse < three_lowest_mse:\n",
    "        three_lowest_mse = mse\n",
    "        three_lowest_k = k + 1\n",
    "\n",
    "two_hyp_mse[two_lowest_k] = two_lowest_mse\n",
    "three_hyp_mse[three_lowest_k] = three_lowest_mse\n",
    "\n",
    "print(two_hyp_mse)\n",
    "print(three_hyp_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
